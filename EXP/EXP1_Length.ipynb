{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27a2c16-a81c-47a4-ad1a-602c518e38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-14 20:05:03,135] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcae742125b4ab4b4799a35cf5b998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenichi.maeda001/anaconda3/envs/LLMP/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/kenichi.maeda001/anaconda3/envs/LLMP/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea4f3ce0cd74336875de352258b9da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bae850c03c4e1cb1fb4e3db43248ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010ee2153f66418f95276e24135d601a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3e174cbacb47aaaa5e67cfa26d6abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd3d55b1d58480f9bcb8d6d94c3e4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1e82599156499abc0a0eefc82e1b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eccb50bedb24cbcbf3064a11d6528fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f7a4ba2b1243f18828dc90c663b956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf30cc692714da6ad6d778c853453c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt': [23, 44, 52, 32, 28, 2, 31, 17, 31, 43], 'ChatGPT': {'parameters': None, 'raw_answers': ['30-40', '50-60', '90-100', '50-60', '50-60', \"I don't see a line in the image provided; there's only a small dot visible on a white background. Therefore, I cannot estimate the length of a line. However, if you're referring to the dot, its size in pixels is difficult to determine with precision without additional context or tools, but it seems to be within a range of 1-5 pixels based on common screen resolutions.\", '55-65', '30-40', '70-80', '90-100'], 'parsed_answers': [[30, 40], [50, 60], [90, 100], [50, 60], [50, 60], [1, 5], [55, 65], [30, 40], [70, 80], [90, 100]], 'mse': 917.8, 'mlae': 11.344365266587058, 'times': [851.719856262207, 31653.744220733643, 1420.7546710968018, 37501.04570388794, 1431.0383796691895, 93128.82161140442, 966.9926166534424, 1175.3485202789307, 15888.050079345703, 5685.687303543091], 'forced_repetitions': 11}, 'LLaVA': {'parameters': None, 'raw_answers': ['Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.'], 'parsed_answers': [[10], [10], [10], [10], [10], [10], [10], [10], [10], [10]], 'mse': 598.1, 'mlae': 11.096797497745936, 'times': [22440.801858901978, 8519.131183624268, 7271.901845932007, 7182.3930740356445, 7129.626512527466, 7176.455974578857, 8191.400051116943, 7423.054456710815, 7311.216592788696, 7115.604877471924], 'forced_repetitions': 0}, 'CustomLLaVA': {'parameters': None, 'raw_answers': ['56', '46', '51', '49', '22', '54', '41', '13', '36', '36'], 'parsed_answers': [[56], [46], [51], [49], [22], [54], [41], [13], [36], [36]], 'mse': 431.3, 'mlae': 10.420091804602315, 'times': [20001.544952392578, 19502.52914428711, 19339.704513549805, 19299.42035675049, 19370.06640434265, 19495.373725891113, 19093.907833099365, 21989.595413208008, 20937.347650527954, 19606.633186340332], 'forced_repetitions': 0}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import LLMP as L\n",
    "\n",
    "query = \"What do you see? If you see a line, can you estimate the length of it in pixels? Please respond with a possible range not larger than 10 pixels and report just the numbers.\"\n",
    "images = [L.GPImage.figure1('length') for i in range(10)]\n",
    "models = [\"ChatGPT\", \"LLaVA\", \"CustomLLaVA\"]\n",
    "\n",
    "results = L.Evaluator.run(images, query, models)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae88a96-4786-428e-b7bc-a3364488cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatGPT_mse = results[\"ChatGPT\"][\"mse\"]\n",
    "chatGPT_mlae = results[\"ChatGPT\"][\"mlae\"]\n",
    "llava_mse = results[\"LLaVA\"][\"mse\"]\n",
    "llava_mlae = results[\"LLaVA\"][\"mlae\"]\n",
    "custom_llava_mse = results[\"CustomLLaVA\"][\"mse\"]\n",
    "custom_llava_mlae = results[\"CustomLLaVA\"][\"mlae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9420df2-bcbf-4268-ae72-1012367da42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT mse:  917.8\n",
      "ChatGPT mlae: 11.344365266587058\n",
      "LLaVA mse:    598.1\n",
      "LLaVA mlae:   11.096797497745936\n",
      "CLLaVA mse:   431.3\n",
      "CLLaVA mlae:  10.420091804602315\n"
     ]
    }
   ],
   "source": [
    "print(\"ChatGPT mse: \", chatGPT_mse)\n",
    "print(\"ChatGPT mlae:\", chatGPT_mlae)\n",
    "print(\"LLaVA mse:   \", llava_mse)\n",
    "print(\"LLaVA mlae:  \", llava_mlae)\n",
    "print(\"CLLaVA mse:  \", custom_llava_mse)\n",
    "print(\"CLLaVA mlae: \", custom_llava_mlae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba39c7f-c1d1-4d47-b62d-c4e74c6b7cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b69c43-fc1a-40da-9e1c-1297fa9b6111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcf87f1-74db-4b82-8357-24fd274759ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-21 08:00:49,182] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2de03d39ec4790a0a835bf567bb3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenichi.maeda001/anaconda3/envs/LLMP/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/kenichi.maeda001/anaconda3/envs/LLMP/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e2b7bf412440c6ab10ad7c177577cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0db9e51b0549d2b97fcc23f6dfb392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c70b6f6f2bf44f7be16f38a390119f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38276afa720245a99c56125465d8bd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc34d2ff0a740109027f70f8037e6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c111cf996a9b48728dc825bf9006fba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13a4648a4ad4b679a687e8ad428df78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6039e98c954b459d4852efd7a59a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caad81c30f294d3a82ad4ee6be96cf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe79d4e269ba4718b38952b1b895761d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deafbc101a1d4f7680ab076e643ee137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b09152f3d945e9a75f2a8cd8fdbbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e275b6e4a9b4cb384e05a8a5b5274bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8213913b6aa341788d372d1da0e3a44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6e558a167f4a09b81a558b32c44129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034237c914d242b59f535381d72ccdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b593d968fd74ccf81378f39b559a2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd3a38784634f9ea0962e2cace62ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d22b18e0a674760b367f9b8ed797ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d3587c438e4a2b9037afaedfd3c9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a32be2fb86495c908200c2a1514ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39033ed7e4bd4f589a46050c825d3878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f4ae582c6c4e9cace8a72cb2d359b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd7e6e80d974a1980dfa643251fd623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36002961680d4febbcbed613f8e9fc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbc3260065d43bc82f0686f7b3e1ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f956e2abf0be447e852286b3d7bf5c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36affbf17e74ae7bfa3382a98ddb052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3b9891289f40b5b5aa9870da9789eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464e35963d034a5abfec61a850b173ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571ab311f7e143efaf7341c91c1f987e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaa42e1e885463786eb712def467546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5cbe0a44684a59b383624fbb0134a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c43a0be44a64fed86192eff4dddb569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869bc43f9c6e4e73bd6ef9f0613ace40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34b60956d064c6782a5cbf8e6dccec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50294dd247174e2fa31dd0f99a6b126d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962fb6e85a3447a289c00772e4a7a7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66956aa2006249459a1ce9907791e0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc8a3585aef4d2f8e7bd515d9968fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a2d981240841c9987485f2a8194bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2c6b281d9c40a5834ee8c19de5ffc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178cb5e72e0a487196ba19e42d6adf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de64fa854b704b3ba4b258ee822c7b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bedfa28a3af4698a20b393a8954f79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66daf9c4c82f44cfada2d9b0e12d9429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61ae5c0147d419198551e98c2800070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef13f3d8b01493b928ebf2c345ee825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0e698edf9e4c6288ade828d8eda5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1e3e58cdc94f65847a908d28976b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a93c2d6a0f447b0a6977763bd18b595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0405dcda6adb4c1bb515d9abc884fb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d202c6c09142288217f2ae1bec4686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b74b760b8f848c8abf8c2b96c22deec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt': [8, 20, 13, 58, 40, 10, 52, 33, 10, 3, 52, 38, 39, 42, 2, 4, 39, 38, 21, 12, 39, 48, 58, 15, 4, 11, 28, 40, 41, 18, 9, 30, 21, 58, 4, 28, 29, 3, 1, 49, 60, 60, 25, 56, 47, 19, 29, 30, 33, 56, 8, 57, 20, 29, 29], 'ChatGPT': {'parameters': None, 'raw_answers': ['30-40', '30-40', '30-40', '70-80', '50-60', '30-40', '70-80', '70-80', '30-40', '5-15', '70-80', '50-60', '70-80', '60-70', \"I'm sorry, but there doesn't appear to be a line in the image youâ€™ve provided. There's a single dot or a very short line that is hard to quantify due to its size and the limitations of the image resolution. If this is considered the line you're referencing, its length in pixels is likely within the range of 1-2 pixels depending on how it is measured.\", '30-40', '70-80', '50-60', '30-40', '30-40', '30-40', '70-80', '70-80', '30-40', '30-40', '30-40', '30-40', '50-60', '70-80', '30-40', '30-40', '30-40', '30-40', '70-80', '10-20', '50-60', '30-40', '30-40', '0-10', '50-60', '70-80', '70-80', '30-40', '70-80', '70-80', '30-40', '30-40', '30-40', '50-60', '70-80', '30-40', '70-80', '30-40', '30-40', '30-40'], 'parsed_answers': [[30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [70.0, 80.0], [50.0, 60.0], [30.0, 40.0], [70.0, 80.0], [70.0, 80.0], [30.0, 40.0], [5.0, 15.0], [70.0, 80.0], [50.0, 60.0], [70.0, 80.0], [60.0, 70.0], [1.0, 2.0], [30.0, 40.0], [70.0, 80.0], [50.0, 60.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [70.0, 80.0], [70.0, 80.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [50.0, 60.0], [70.0, 80.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [70.0, 80.0], [10.0, 20.0], [50.0, 60.0], [30.0, 40.0], [30.0, 40.0], [0.0, 10.0], [50.0, 60.0], [70.0, 80.0], [70.0, 80.0], [30.0, 40.0], [70.0, 80.0], [70.0, 80.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0], [50.0, 60.0], [70.0, 80.0], [30.0, 40.0], [70.0, 80.0], [30.0, 40.0], [30.0, 40.0], [30.0, 40.0]], 'mean': 47.74545454545454, 'std': 20.647005666081625, 'mse': 427.3454545454546, 'mlae': 10.842734253798605, 'times': [827.9352188110352, 1193.7501430511475, 1037.7907752990723, 807.2357177734375, 815.3035640716553, 15970.63136100769, 898.7040519714355, 835.1144790649414, 845.555305480957, 338778.3651351929, 996.4818954467773, 1330.0349712371826, 1010.1010799407959, 1296.614646911621, 29566.34545326233, 27184.6342086792, 27626.58381462097, 1076.0056972503662, 1406.4509868621826, 878.0441284179688, 14880.826473236084, 1387.718915939331, 17831.61759376526, 28925.817489624023, 826.9133567810059, 1876.253366470337, 858.2808971405029, 1294.856071472168, 895.5423831939697, 886.7621421813965, 806.0622215270996, 766.526460647583, 933.0582618713379, 706.8073749542236, 14658.061981201172, 14518.315076828003, 1127.258539199829, 27460.16788482666, 420993.0651187897, 838.5560512542725, 1025.0797271728516, 27587.421417236328, 849.0331172943115, 916.6131019592285, 1125.6775856018066, 1029.4387340545654, 754.9681663513184, 14503.66473197937, 1317.4395561218262, 979.3884754180908, 818.6571598052979, 1061.330795288086, 805.1409721374512, 1032.9954624176025, 14625.401973724365], 'forced_repetitions': 75}, 'LLaVA': {'parameters': None, 'raw_answers': ['Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.', 'Yes, I can see a line in the image. The line is approximately 10 pixels long.'], 'parsed_answers': [[10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0], [10.0]], 'mean': 10.0, 'std': 0.0, 'mse': 713.6727272727272, 'mlae': 11.072033610801762, 'times': [20827.462911605835, 7483.172178268433, 7521.7344760894775, 7094.950914382935, 7382.997989654541, 6988.706827163696, 7037.641763687134, 7084.67960357666, 7499.151229858398, 7287.996292114258, 7347.677230834961, 7039.4933223724365, 7128.506660461426, 7036.278963088989, 7158.624172210693, 7549.962043762207, 7028.655529022217, 7138.882398605347, 7079.626798629761, 7073.6753940582275, 7569.6516036987305, 7074.723243713379, 7260.549068450928, 7321.945428848267, 7057.30676651001, 7189.193487167358, 7003.880500793457, 7109.646797180176, 7349.916696548462, 7039.2491817474365, 7257.928133010864, 7338.548183441162, 7060.333251953125, 7309.226989746094, 7162.915229797363, 7032.128095626831, 7229.560852050781, 7022.5114822387695, 6979.206085205078, 7374.930858612061, 7060.090065002441, 7126.992464065552, 7149.429559707642, 7100.718259811401, 7199.048757553101, 7293.625116348267, 6993.03126335144, 7069.823265075684, 6998.109817504883, 7108.78849029541, 6973.619222640991, 7104.604005813599, 7122.016191482544, 7839.752435684204, 7211.7674350738525], 'forced_repetitions': 0}, 'CustomLLaVA': {'parameters': None, 'raw_answers': ['26', '21', '44', '21', '29', '28', '51', '55', '49', '13', '53', '51', '25', '24', '23', '1', '17', '36', '1', '55', '41', '51', '51', '49', '16', '1', '41', '39', '49', '39', '27', '49', '55', '19', '49', '54', '49', '12', '42', '51', '46', '51', '49', '41', '47', '49', '51', '19', '57', '49', '33', '13', '23', '57', '13'], 'parsed_answers': [[26.0], [21.0], [44.0], [21.0], [29.0], [28.0], [51.0], [55.0], [49.0], [13.0], [53.0], [51.0], [25.0], [24.0], [23.0], [1.0], [17.0], [36.0], [1.0], [55.0], [41.0], [51.0], [51.0], [49.0], [16.0], [1.0], [41.0], [39.0], [49.0], [39.0], [27.0], [49.0], [55.0], [19.0], [49.0], [54.0], [49.0], [12.0], [42.0], [51.0], [46.0], [51.0], [49.0], [41.0], [47.0], [49.0], [51.0], [19.0], [57.0], [49.0], [33.0], [13.0], [23.0], [57.0], [13.0]], 'mean': 36.45454545454545, 'std': 16.29815179908801, 'mse': 477.58181818181816, 'mlae': 10.80070690523046, 'times': [23733.386278152466, 19433.746337890625, 20122.086763381958, 19578.855752944946, 19716.825246810913, 20644.595623016357, 18867.549657821655, 20663.68794441223, 19761.561632156372, 22098.1125831604, 19186.318397521973, 19192.41237640381, 19353.368043899536, 19539.01505470276, 20708.26482772827, 18621.400833129883, 18857.967615127563, 21276.151180267334, 18789.723873138428, 19707.690000534058, 19724.756240844727, 19290.799379348755, 19880.664587020874, 21629.22501564026, 18679.33416366577, 18903.28359603882, 18989.0079498291, 18626.264810562134, 19708.68968963623, 21663.198709487915, 21361.73701286316, 19704.305410385132, 19223.620891571045, 19052.120447158813, 19192.681074142456, 18872.783660888672, 19118.335247039795, 19444.78464126587, 19451.777935028076, 19093.94931793213, 19170.435190200806, 19129.81939315796, 18812.618494033813, 18648.114442825317, 19655.910968780518, 19200.515508651733, 18920.5539226532, 19508.992433547974, 19902.435779571533, 19235.735177993774, 19575.158834457397, 19368.579387664795, 18996.963024139404, 19015.611171722412, 19769.095420837402], 'forced_repetitions': 0}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import LLMP as L\n",
    "\n",
    "query = \"What do you see? If you see a line, can you estimate the length of it in pixels? Please respond with a possible range not larger than 10 pixels and report just the numbers.\"\n",
    "images = [L.GPImage.figure1('length') for i in range(55)]\n",
    "models = [\"ChatGPT\", \"LLaVA\", \"CustomLLaVA\"]\n",
    "\n",
    "results = L.Evaluator.run(images, query, models)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afe1ef1-debc-4f4c-941f-38e0d090a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatGPT_mse = results[\"ChatGPT\"][\"mse\"]\n",
    "chatGPT_mlae = results[\"ChatGPT\"][\"mlae\"]\n",
    "chatGPT_mean = results[\"ChatGPT\"][\"mean\"]\n",
    "chatGPT_std = results[\"ChatGPT\"][\"std\"]\n",
    "llava_mse = results[\"LLaVA\"][\"mse\"]\n",
    "llava_mlae = results[\"LLaVA\"][\"mlae\"]\n",
    "llava_mean = results[\"LLaVA\"][\"mean\"]\n",
    "llava_std = results[\"LLaVA\"][\"std\"]\n",
    "custom_llava_mse = results[\"CustomLLaVA\"][\"mse\"]\n",
    "custom_llava_mlae = results[\"CustomLLaVA\"][\"mlae\"]\n",
    "custom_llava_mean = results[\"CustomLLaVA\"][\"mean\"]\n",
    "custom_llava_std = results[\"CustomLLaVA\"][\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853d7079-3c0f-4703-8324-82620c683aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT mse:  427.3454545454546\n",
      "ChatGPT mlae: 10.842734253798605\n",
      "ChatGPT mean: 47.74545454545454\n",
      "ChatGPT std: 20.647005666081625\n",
      "LLaVA mse:    713.6727272727272\n",
      "LLaVA mlae:   11.072033610801762\n",
      "LLaVA mean:   10.0\n",
      "LLaVA std:   0.0\n",
      "CLLaVA mse:   477.58181818181816\n",
      "CLLaVA mlae:  10.80070690523046\n",
      "CLLaVA mean:  36.45454545454545\n",
      "CLLaVA std:  16.29815179908801\n"
     ]
    }
   ],
   "source": [
    "print(\"ChatGPT mse: \", chatGPT_mse)\n",
    "print(\"ChatGPT mlae:\", chatGPT_mlae)\n",
    "print(\"ChatGPT mean:\", chatGPT_mean)\n",
    "print(\"ChatGPT std:\", chatGPT_std)\n",
    "print(\"LLaVA mse:   \", llava_mse)\n",
    "print(\"LLaVA mlae:  \", llava_mlae)\n",
    "print(\"LLaVA mean:  \", llava_mean)\n",
    "print(\"LLaVA std:  \", llava_std)\n",
    "print(\"CLLaVA mse:  \", custom_llava_mse)\n",
    "print(\"CLLaVA mlae: \", custom_llava_mlae)\n",
    "print(\"CLLaVA mean: \", custom_llava_mean)\n",
    "print(\"CLLaVA std: \", custom_llava_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f269f-d85a-4bed-be7a-d8fe13a69290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
