{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc1fa07",
   "metadata": {},
   "source": [
    "### Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f5bd9a-26ab-440c-b83c-d329f00d717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images and dataset for task: position_common_scale\n",
      "Generating images and dataset for task: position_non_aligned_scale\n",
      "Generating images and dataset for task: length\n",
      "Generating images and dataset for task: direction\n",
      "Generating images and dataset for task: angle\n",
      "Generating images and dataset for task: area\n",
      "Generating images and dataset for task: volume\n",
      "Generating images and dataset for task: curvature\n",
      "Generating images and dataset for task: shading\n",
      "Images saved in 'finetuning-EXP1-5000-10epochs-backup/images' and combined dataset saved as 'combined_dataset.json' in 'finetuning-EXP1-5000-10epochs-backup/json'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.draw\n",
    "import json\n",
    "\n",
    "# Add LLMP module to system path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")  # Adds the current directory to the Python path\n",
    "\n",
    "import LLMP as L\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Define the main output directory\n",
    "main_output_dir = \"finetuning-EXP1-5000-10epochs-backup\"\n",
    "\n",
    "# Subdirectories for images and JSON files\n",
    "image_output_dir = os.path.join(main_output_dir, \"images\")\n",
    "json_output_dir = os.path.join(main_output_dir, \"json\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "os.makedirs(json_output_dir, exist_ok=True)\n",
    "\n",
    "# List of tasks and their respective questions\n",
    "tasks = {\n",
    "    \"position_common_scale\": \"Please estimate the vertical position of the block relative to the line on the left (Top is 0, Bottom is 60). So the range is 0 - 60. No explanation.\",\n",
    "    \"position_non_aligned_scale\": \"Please estimate the vertical position of the block relative to the line on the left (Top is 0, Bottom is 60). So the range is 0 - 60. No explanation.\",\n",
    "    \"length\": \"Please estimate the length of the vertical line (from top to bottom). The height of the whole image is 100. No explanation.\",\n",
    "    \"direction\": \"Please estimate the direction of the line relative to the starting dot in the range 0 - 359 degrees. No explanation.\",\n",
    "    \"angle\": \"Please estimate the angle (0-90 degrees). No explanation.\",\n",
    "    \"area\": \"Please estimate the area covered by the circle. The whole image is 100x100 with an area of 10000. No explanation.\",\n",
    "    \"volume\": \"Please estimate the volume of the cube. The cube size is relative to the image size of 100x100. No explanation.\",\n",
    "    \"curvature\": \"Please estimate the curvature of the line. (0 is no curvature - 1 is the maximum curvature) The more bend the line is, the higher the curvature. No explanation.\",\n",
    "    \"shading\": \"Please estimate the shading density or texture density (range 0 to 100). No explanation.\"\n",
    "}\n",
    "\n",
    "# Number of images to generate for each task\n",
    "num_images_per_task = 5000\n",
    "\n",
    "# List to store all data from all tasks\n",
    "combined_dataset = []\n",
    "\n",
    "# Loop through each task\n",
    "for task, question in tasks.items():\n",
    "    print(f\"Generating images and dataset for task: {task}\")\n",
    "    \n",
    "    # Set up a loop to generate images and collect their labels\n",
    "    for i in range(num_images_per_task):\n",
    "        # Generate the image and label for the task using GPImage\n",
    "    \n",
    "        image_array, label = L.GPImage.figure1(task)  # Ensure GPImage is defined or imported\n",
    "        \n",
    "        # Convert the array to uint8 format (values from 0 to 255)\n",
    "        image_array_uint8 = (image_array * 255).astype(np.uint8)\n",
    "\n",
    "        # Convert the NumPy array to a PIL image\n",
    "        pil_image = Image.fromarray(image_array_uint8)\n",
    "\n",
    "        # Generate a unique ID for the image\n",
    "        unique_id = str(uuid.uuid4())\n",
    "\n",
    "        # Save the image with the unique ID\n",
    "        image_filename = os.path.join(image_output_dir, f\"{unique_id}.jpg\")\n",
    "        pil_image.save(image_filename)\n",
    "\n",
    "        # Create a JSON entry for the dataset\n",
    "        json_entry = {\n",
    "            'id': unique_id,\n",
    "            'image': f\"{unique_id}.jpg\",\n",
    "            'question': question,\n",
    "            'value': label\n",
    "        }\n",
    "\n",
    "        # Append the JSON entry to the combined dataset list\n",
    "        combined_dataset.append(json_entry)\n",
    "\n",
    "# Save the combined dataset as a single JSON file in the JSON folder\n",
    "combined_json_filename = \"combined_dataset.json\"\n",
    "combined_json_filepath = os.path.join(json_output_dir, combined_json_filename)\n",
    "\n",
    "with open(combined_json_filepath, 'w') as json_file:\n",
    "    json.dump(combined_dataset, json_file, indent=4)\n",
    "\n",
    "print(f\"Images saved in '{image_output_dir}' and combined dataset saved as '{combined_json_filename}' in '{json_output_dir}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748356f",
   "metadata": {},
   "source": [
    "### Distribution of each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86ed4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/huuthanhvy.nguyen001/tmp/LLMP/EXP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba640839",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ./EXPs-5000-3pochs/finetune/EXPs-5000-3pochs/json/combined_dataset.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m json_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./EXPs-5000-3pochs/finetune/EXPs-5000-3pochs/json/combined_dataset.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load JSON file into a DataFrame\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Dictionary to map simplified task names to full questions\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sbatch2/lib/python3.10/site-packages/pandas/io/json/_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/anaconda3/envs/sbatch2/lib/python3.10/site-packages/pandas/io/json/_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sbatch2/lib/python3.10/site-packages/pandas/io/json/_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    959\u001b[0m ):\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    968\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File ./EXPs-5000-3pochs/finetune/EXPs-5000-3pochs/json/combined_dataset.json does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = './EXPs-5000-3pochs/finetune/outputEXP1-5000-3poch/json/combined_dataset.json'\n",
    "\n",
    "# Load JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to map simplified task names to full questions\n",
    "task_descriptions = {\n",
    "    \"position_common_scale\": \"Please estimate the vertical position of the block relative to the line on the left (Top is 0, Bottom is 60). So the range is 0 - 60. No explanation.\",\n",
    "    \"position_non_aligned_scale\": \"Please estimate the vertical position of the block relative to a misaligned line on the left. (Top is 0, Bottom is 60). No explanation.\",\n",
    "    \"length\": \"Please estimate the length of the vertical line (from top to bottom). The height of the whole image is 100. No explanation.\",\n",
    "    \"direction\": \"Please estimate the direction of the line relative to the starting dot in the range 0 - 359 degrees. No explanation.\",\n",
    "    \"angle\": \"Please estimate the angle (0-90 degrees). No explanation.\",\n",
    "    \"area\": \"Please estimate the area covered by the circle. The whole image is 100x100 with an area of 10000. No explanation.\",\n",
    "    \"volume\": \"Please estimate the volume of the cube. The cube size is relative to the image size of 100x100. No explanation.\",\n",
    "    \"curvature\": \"Please estimate the curvature of the line. (0 is no curvature - 1 is the maximum curvature) The more bend the line is, the higher the curvature. No explanation.\",\n",
    "    \"shading\": \"Please estimate the shading density or texture density (range 0 to 100). No explanation.\"\n",
    "}\n",
    "\n",
    "# Function to get the distribution for a specified task, allowing either simplified or full task description\n",
    "def get_task_distribution(df, task_key):\n",
    "    # Check if the task_key is in the dictionary; if so, use the full description\n",
    "    if task_key in task_descriptions:\n",
    "        task_description = task_descriptions[task_key]\n",
    "    elif task_key in task_descriptions.values():\n",
    "        task_description = task_key\n",
    "    else:\n",
    "        print(\"Task not found. Please provide a valid task name or description.\")\n",
    "        return\n",
    "\n",
    "    # Set display options to show all rows and columns\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)  # Set to None to display full cell content\n",
    "\n",
    "    # Filter the DataFrame to include only rows where 'task' matches the given task description\n",
    "    task_df = df[df['question'] == task_description]\n",
    "\n",
    "    # Group by 'value' within the filtered DataFrame to get the distribution and count\n",
    "    distribution = task_df.groupby(['value']).size().reset_index(name='count')\n",
    "\n",
    "    # Sort by 'value' in ascending order\n",
    "    distribution = distribution.sort_values(by='value', ascending=True)\n",
    "\n",
    "    # Display the sorted distribution DataFrame\n",
    "    print(distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06410343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     value  count\n",
      "0      1.0    252\n",
      "1      8.0    249\n",
      "2     27.0    248\n",
      "3     64.0    227\n",
      "4    125.0    243\n",
      "5    216.0    260\n",
      "6    343.0    247\n",
      "7    512.0    261\n",
      "8    729.0    264\n",
      "9   1000.0    268\n",
      "10  1331.0    237\n",
      "11  1728.0    254\n",
      "12  2197.0    252\n",
      "13  2744.0    243\n",
      "14  3375.0    261\n",
      "15  4096.0    225\n",
      "16  4913.0    247\n",
      "17  5832.0    248\n",
      "18  6859.0    258\n",
      "19  8000.0    256\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "get_task_distribution(df, \"volume\")  # Using simplified task name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9a229b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    value  count\n",
      "0     0.0     87\n",
      "1     1.0     72\n",
      "2     2.0     89\n",
      "3     3.0     86\n",
      "4     4.0     91\n",
      "5     5.0     89\n",
      "6     6.0     76\n",
      "7     7.0     81\n",
      "8     8.0     84\n",
      "9     9.0     88\n",
      "10   10.0     82\n",
      "11   11.0     85\n",
      "12   12.0     92\n",
      "13   13.0     77\n",
      "14   14.0     80\n",
      "15   15.0     77\n",
      "16   16.0     99\n",
      "17   17.0     82\n",
      "18   18.0     70\n",
      "19   19.0     95\n",
      "20   20.0     94\n",
      "21   21.0    341\n",
      "22   22.0    332\n",
      "23   23.0    336\n",
      "24   24.0    309\n",
      "25   25.0    345\n",
      "26   26.0    336\n",
      "27   27.0    352\n",
      "28   28.0    315\n",
      "29   29.0    348\n",
      "30   30.0    328\n",
      "31   31.0    322\n",
      "32   32.0    330\n",
      "33   33.0    310\n",
      "34   34.0    351\n",
      "35   35.0    329\n",
      "36   36.0    346\n",
      "37   37.0    342\n",
      "38   38.0    349\n",
      "39   39.0    335\n",
      "40   40.0    333\n",
      "41   41.0     81\n",
      "42   42.0     78\n",
      "43   43.0     82\n",
      "44   44.0     73\n",
      "45   45.0     71\n",
      "46   46.0     83\n",
      "47   47.0     78\n",
      "48   48.0     86\n",
      "49   49.0     59\n",
      "50   50.0     88\n",
      "51   51.0     74\n",
      "52   52.0     84\n",
      "53   53.0     89\n",
      "54   54.0     90\n",
      "55   55.0     88\n",
      "56   56.0     77\n",
      "57   57.0     93\n",
      "58   58.0     98\n",
      "59   59.0     63\n"
     ]
    }
   ],
   "source": [
    "get_task_distribution(df, \"position_common_scale\")  # Using simplified task name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eae729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          value  count\n",
      "0      3.141593    142\n",
      "1     12.566371    116\n",
      "2     28.274334    139\n",
      "3     50.265482    139\n",
      "4     78.539816    136\n",
      "5    113.097336    118\n",
      "6    153.938040    127\n",
      "7    201.061930    125\n",
      "8    254.469005    126\n",
      "9    314.159265    149\n",
      "10   380.132711    109\n",
      "11   452.389342    146\n",
      "12   530.929158    139\n",
      "13   615.752160    128\n",
      "14   706.858347    119\n",
      "15   804.247719    110\n",
      "16   907.920277    114\n",
      "17  1017.876020    113\n",
      "18  1134.114948    144\n",
      "19  1256.637061    125\n",
      "20  1385.442360    114\n",
      "21  1520.530844    121\n",
      "22  1661.902514     86\n",
      "23  1809.557368    103\n",
      "24  1963.495408    129\n",
      "25  2123.716634    100\n",
      "26  2290.221044    139\n",
      "27  2463.008640    134\n",
      "28  2642.079422    141\n",
      "29  2827.433388    105\n",
      "30  3019.070540    126\n",
      "31  3216.990877    138\n",
      "32  3421.194400    131\n",
      "33  3631.681108    130\n",
      "34  3848.451001    112\n",
      "35  4071.504079    127\n",
      "36  4300.840343    126\n",
      "37  4536.459792    119\n",
      "38  4778.362426    134\n",
      "39  5026.548246    121\n"
     ]
    }
   ],
   "source": [
    "get_task_distribution(df, \"area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09e6960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    value  count\n",
      "0   0.000     53\n",
      "1   0.001     59\n",
      "2   0.002     49\n",
      "3   0.003     52\n",
      "4   0.004     48\n",
      "5   0.006     69\n",
      "6   0.007     78\n",
      "7   0.008     50\n",
      "8   0.009     69\n",
      "9   0.010     56\n",
      "10  0.011     58\n",
      "11  0.012     53\n",
      "12  0.013     76\n",
      "13  0.014     58\n",
      "14  0.016     58\n",
      "15  0.017     62\n",
      "16  0.018     55\n",
      "17  0.019     84\n",
      "18  0.020     71\n",
      "19  0.021     54\n",
      "20  0.022     59\n",
      "21  0.023     62\n",
      "22  0.024     62\n",
      "23  0.026     63\n",
      "24  0.027     86\n",
      "25  0.028     65\n",
      "26  0.029     57\n",
      "27  0.030     68\n",
      "28  0.031     74\n",
      "29  0.032     67\n",
      "30  0.033     70\n",
      "31  0.034     51\n",
      "32  0.036     65\n",
      "33  0.037     58\n",
      "34  0.038     54\n",
      "35  0.039     62\n",
      "36  0.040     49\n",
      "37  0.041     59\n",
      "38  0.042     64\n",
      "39  0.043     75\n",
      "40  0.044     59\n",
      "41  0.046     58\n",
      "42  0.047     57\n",
      "43  0.048     69\n",
      "44  0.049     63\n",
      "45  0.050     63\n",
      "46  0.051     53\n",
      "47  0.052     60\n",
      "48  0.053     70\n",
      "49  0.054     75\n",
      "50  0.056     61\n",
      "51  0.057     61\n",
      "52  0.058     73\n",
      "53  0.059     68\n",
      "54  0.060     75\n",
      "55  0.061     67\n",
      "56  0.062     65\n",
      "57  0.063     56\n",
      "58  0.064     67\n",
      "59  0.066     61\n",
      "60  0.067     57\n",
      "61  0.068     56\n",
      "62  0.069     61\n",
      "63  0.070     60\n",
      "64  0.071     51\n",
      "65  0.072     70\n",
      "66  0.073     81\n",
      "67  0.074     55\n",
      "68  0.076     56\n",
      "69  0.077     62\n",
      "70  0.078     65\n",
      "71  0.079     56\n",
      "72  0.080     78\n",
      "73  0.081     58\n",
      "74  0.082     69\n",
      "75  0.083     54\n",
      "76  0.084     52\n",
      "77  0.086     61\n",
      "78  0.087     62\n",
      "79  0.088     73\n"
     ]
    }
   ],
   "source": [
    "get_task_distribution(df, \"curvature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6c8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    value  count\n",
      "0     1.0     49\n",
      "1     2.0     57\n",
      "2     3.0     46\n",
      "3     4.0     43\n",
      "4     5.0     44\n",
      "5     6.0     51\n",
      "6     7.0     54\n",
      "7     8.0     58\n",
      "8     9.0     46\n",
      "9    10.0     53\n",
      "10   11.0     40\n",
      "11   12.0     55\n",
      "12   13.0     63\n",
      "13   14.0     46\n",
      "14   15.0     53\n",
      "15   16.0     50\n",
      "16   17.0     41\n",
      "17   18.0     42\n",
      "18   19.0     60\n",
      "19   20.0     54\n",
      "20   21.0     45\n",
      "21   22.0     51\n",
      "22   23.0     52\n",
      "23   24.0     59\n",
      "24   25.0     42\n",
      "25   26.0     57\n",
      "26   27.0     51\n",
      "27   28.0     42\n",
      "28   29.0     41\n",
      "29   30.0     38\n",
      "30   31.0     56\n",
      "31   32.0     59\n",
      "32   33.0     50\n",
      "33   34.0     45\n",
      "34   35.0     55\n",
      "35   36.0     60\n",
      "36   37.0     55\n",
      "37   38.0     66\n",
      "38   39.0     50\n",
      "39   40.0     49\n",
      "40   41.0     41\n",
      "41   42.0     48\n",
      "42   43.0     57\n",
      "43   44.0     54\n",
      "44   45.0     52\n",
      "45   46.0     54\n",
      "46   47.0     59\n",
      "47   48.0     32\n",
      "48   49.0     40\n",
      "49   50.0     43\n",
      "50   51.0     42\n",
      "51   52.0     48\n",
      "52   53.0     50\n",
      "53   54.0     54\n",
      "54   55.0     56\n",
      "55   56.0     55\n",
      "56   57.0     60\n",
      "57   58.0     57\n",
      "58   59.0     44\n",
      "59   60.0     47\n",
      "60   61.0     51\n",
      "61   62.0     51\n",
      "62   63.0     56\n",
      "63   64.0     52\n",
      "64   65.0     48\n",
      "65   66.0     51\n",
      "66   67.0     55\n",
      "67   68.0     49\n",
      "68   69.0     48\n",
      "69   70.0     43\n",
      "70   71.0     41\n",
      "71   72.0     50\n",
      "72   73.0     61\n",
      "73   74.0     56\n",
      "74   75.0     46\n",
      "75   76.0     51\n",
      "76   77.0     43\n",
      "77   78.0     41\n",
      "78   79.0     44\n",
      "79   80.0     49\n",
      "80   81.0     57\n",
      "81   82.0     39\n",
      "82   83.0     46\n",
      "83   84.0     37\n",
      "84   85.0     64\n",
      "85   86.0     50\n",
      "86   87.0     57\n",
      "87   88.0     56\n",
      "88   89.0     70\n",
      "89   90.0     58\n",
      "90   91.0     45\n",
      "91   92.0     62\n",
      "92   93.0     42\n",
      "93   94.0     42\n",
      "94   95.0     42\n",
      "95   96.0     51\n",
      "96   97.0     40\n",
      "97   98.0     50\n",
      "98   99.0     40\n",
      "99  100.0     45\n"
     ]
    }
   ],
   "source": [
    "get_task_distribution(df, \"shading\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbatch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
